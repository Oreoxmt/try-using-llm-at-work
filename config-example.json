{
  "model": "./models/llama-2-13b-chat/ggml-model-f16.gguf",
  "params": {
    "contextLength": 4096,
    "batchSize": 512,
    "gpuLayers": 43
  },
  "eval": {
    "batchSize": 512,
    "threadCount": 1
  },
  "predict": {
    "repeatPenaltySize": 16,
    "repeatPenalty": 1.1,
    "alphaPresence": 0.0,
    "alphaFrequency": 0.0,
    "topK": 40,
    "tailFreeZ": 1.0,
    "typicalP": 1.0,
    "topP": 0.95,
    "temperature": 0.8
  },
  "bind": "127.0.0.1:2333",
  "connect": "127.0.0.1:2333"
}
